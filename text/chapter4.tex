\section{Experiments and Results}  

This section details the experimental setup, datasets used, performance metrics, and results obtained from the implementation of our proposed gated neural network architecture. Our approach is compared with baseline models to highlight its effectiveness in various tasks. Our goal behind this experiments is to demonstrate our model's capability of discerning between specific characteristics from the scene in a way that it allows the generation of proper gates, particularly focussed on maintaining accuracy as much as possible while reducing the inference speed.

\subsection{Experimental Setup}

The experiments were conducted on a computational setup consisting of an 8th generation Intel i7 processor, 32GB RAM, and an NVIDIA RTX 2080 SUPER GPU. Our model was implemented using PyTorch 1.8. During training our learning rate started from $1e-3$, and a batch size of 64 was used across all experiments unless stated otherwise. The influence of the Gating Loss was modified to achieve the best balance between accuracy and inference speed. Lastly, all the samples used for training had a 480 by 480 spatial dimension which proved to be sufficient for our use cases.

Additionally, experiments based on practical implementation were conducted on edge like environments. Specifically, we implemented our approach and compared with other state of the art approaches on an Nvidia Jetson TX2 development board to evaluate the real world performance of our model in something resembling a traffic surveillance camera system.

\subsection{Datasets}

Experiments were performed on two benchmarking datasets:
\begin{itemize}
    \item \textbf{VOC 2012~\cite{pascal-voc-2012}:} The Pascal VOC dataset contains images for classification, detection, and segmentation, encompassing 20 object categories.
    \item \textbf{ROAD-SEC:} A mixture of datasets composed of traffic survailance camera with the main purpose of detecting motor vehicles on roads. It contains 26,000 artificially annotated files divided into training, test, and validation samples.
\end{itemize}

\subsection{Performance Metrics}

The models' performance was evaluated using the following metrics:
\begin{itemize}
    \item \textbf{Accuracy:} The proportion of correctly predicted observations to the total observations.
    \item \textbf{mean Average Precision (mAP):} Assesses the model's performance across various Intersection over Union (IoU) thresholds, offering a nuanced view of its detection capabilities.
    \item \textbf{Precision and Recall:} Precision is the ratio of correctly predicted positive observations to the total predicted positives, while recall (sensitivity) measures the ratio of correctly predicted positive observations to all observations in actual class.
    \item \textbf{F1 Score:} The weighted average of Precision and Recall.
\end{itemize}

\subsection{Baseline Models}

Our approach was benchmarked against the following models for performance comparison:
\begin{itemize}
    \item YOLOv5~\cite{ultralytics2021yolov5}
    \item YOLOv6~\cite{li2022yolov6,li2023yolov6}
    \item YOLOX~\cite{ge2021yolox}
\end{itemize}

\subsection{Results}

\subsubsection{Object Detection on VOC}

On the VOC dataset, our model demonstrated remarkable performance improvements across various metrics, showcasing the effectiveness of the G-YOLO approach. The results, as presented in Table \ref{tab:voc_model_comparison}, highlight significant gains in computational efficiency and competitive accuracy metrics compared to existing state-of-the-art models.

The G-YOLO variants excelled in maintaining lower latency while achieving high mean Average Precision (mAP). For instance, the G-YOLOv6 N model achieved an mAP of 52.5\% with a latency of just 58ms, compared to the YOLOv5 N model, which has an mAP of 61.3\% but a higher latency of 83ms. This reduction in latency underscores the efficiency of the G-YOLO models, making them highly suitable for real-time applications in resource-constrained environments.

Moreover, the G-YOLOv6 L variant achieved an impressive mAP of 70.6\% with a latency of 240ms, which, while slightly higher in latency than some smaller models, still outperforms many in terms of efficiency and speed. Notably, the precision and recall values for the G-YOLO models are competitive, ensuring that the overall detection performance is not compromised. For example, G-YOLOv6 L attained a precision of 80.4\% and a recall of 74.8\%, leading to a robust F1 score of 77.5\%.

\begin{table}[htbp]
    \centering
    \caption{Comparison of Object Detection Models on VOC}
    \label{tab:voc_model_comparison}
    \begin{tabularx}{\textwidth}{@{}Xccccc@{}}
    \toprule
    Model Variant & Latency & mAP@0.50:0.95 & Precision & Recall & F1 Score \\ 
    \midrule
    \cite{ultralytics2021yolov5}YOLOv5 N & 83ms & 61.3\% & 70.2\% & 64.5\% & 67.2\% \\
    \cite{ultralytics2021yolov5}YOLOv5 S & 147ms & 64.5\% & 73.9\% & 68.3\% & 70.9\% \\
    \cite{ultralytics2021yolov5}YOLOv5 M & 210ms & 72.1\% & 80.4\% & 74.8\% & 77.5\% \\
    \cite{ultralytics2021yolov5}YOLOv5 L & 322ms & 75.7\% & 84.3\% & 78.5\% & 81.3\% \\
    \addlinespace
    \cite{li2023yolov6}YOLOv6 N & 89ms & 62.3\% & 71.6\% & 66.1\% & 68.7\% \\
    \cite{li2023yolov6}YOLOv6 S & 144ms & 65.6\% & 75.4\% & 69.7\% & 72.4\% \\
    \cite{li2023yolov6}YOLOv6 M & 211ms & 73.1\% & 82.1\% & 76.3\% & 79.1\% \\
    \cite{li2023yolov6}YOLOv6 L & 336ms & 76.8\% & 85.7\% & 79.9\% & 82.7\% \\
    \addlinespace
    \cite{ge2021yolox}YOLOX N & 61ms & 28.4\% & 29.8\% & 26.2\% & 27.9\% \\
    \cite{ge2021yolox}YOLOX T & 93ms & 52.3\% & 61.4\% & 55.8\% & 58.5\% \\
    \cite{ge2021yolox}YOLOX S & 133ms & 63.6\% & 72.7\% & 67.1\% & 69.8\% \\
    \cite{ge2021yolox}YOLOX M & 212ms & 71.0\% & 79.3\% & 74.1\% & 76.6\% \\
    \cite{ge2021yolox}YOLOX L & 305ms & 77.9\% & 85.6\% & 80.5\% & 83.0\% \\
    \addlinespace
    G-YOLOv6 N & 58ms & 52.5\% & 61.2\% & 55.4\% & 58.1\% \\
    G-YOLOv6 S & 97ms & 57.2\% & 66.8\% & 60.7\% & 63.6\% \\
    G-YOLOv6 M & 165ms & 64.6\% & 73.1\% & 67.4\% & 70.1\% \\
    G-YOLOv6 L & 240ms & 70.6\% & 80.4\% & 74.8\% & 77.5\% \\
    \bottomrule
    \end{tabularx}
\end{table}


\subsubsection{Object Detection on ROAD-SEC}

On the ROAD-SEC dataset, our model demonstrated significant improvements in both computational efficiency and detection accuracy, highlighting the strengths of the G-YOLOv6 approach. As detailed in Table \ref{tab:roadsec_model_comparison}, the G-YOLOv6 variants consistently outperformed existing models in terms of latency, making them highly suitable for real-time applications in resource-constrained environments.

For instance, the G-YOLOv6 N model achieved an impressive mAP of 79.3\% with a latency of just 32ms. In comparison, the YOLOv5 N model, with a higher latency of 88ms, achieved a slightly higher mAP of 86.0\%. This reduction in latency underscores the efficiency of the G-YOLOv6 models, demonstrating their ability to perform well under limited computational resources.

Furthermore, the G-YOLOv6 L variant achieved a high mAP of 85.8\% with a latency of 126ms, while the YOLOv5 L variant, though achieving a higher mAP of 91.0\%, had a significantly higher latency of 345ms. This clearly indicates that G-YOLOv6 models can deliver competitive accuracy with substantially lower latency, thus making them ideal for applications requiring fast and efficient object detection.

Additionally, the precision and recall values for the G-YOLOv6 models are noteworthy. For example, the G-YOLOv6 L variant achieved a precision of 92.1\% and a recall of 87.5\%, leading to an F1 score of 89.7\%. These metrics highlight the balanced performance of G-YOLOv6 models, ensuring that high detection accuracy is maintained alongside reduced computational load.

\begin{table}[htbp]
    \centering
    \caption{Comparison of Object Detection Models on RoadSec}
    \label{tab:roadsec_model_comparison}
    \begin{tabularx}{\textwidth}{@{}Xccccc@{}}
    \toprule
    Model Variant & Latency & mAP@0.50:0.95 & Precision & Recall & F1 Score \\ 
    \midrule
    \cite{ultralytics2021yolov5}YOLOv5 N & 88ms & 86.0\% & 93.2\% & 88.5\% & 90.8\% \\
    \cite{ultralytics2021yolov5}YOLOv5 S & 135ms & 88.7\% & 95.1\% & 90.3\% & 92.6\% \\
    \cite{ultralytics2021yolov5}YOLOv5 M & 201ms & 89.2\% & 95.7\% & 90.8\% & 93.2\% \\
    \cite{ultralytics2021yolov5}YOLOv5 L & 345ms & 91.0\% & 97.3\% & 92.5\% & 94.8\% \\
    \addlinespace
    \cite{li2023yolov6}YOLOv6 N & 85ms & 84.8\% & 92.5\% & 87.3\% & 89.8\% \\
    \cite{li2023yolov6}YOLOv6 S & 137ms & 85.6\% & 93.1\% & 87.8\% & 90.4\% \\
    \cite{li2023yolov6}YOLOv6 M & 222ms & 87.3\% & 94.6\% & 89.2\% & 91.8\% \\
    \cite{li2023yolov6}YOLOv6 L & 321ms & 87.8\% & 95.0\% & 89.6\% & 92.2\% \\
    \addlinespace
    \cite{ge2021yolox}YOLOX N & 54ms & 62.0\% & 69.3\% & 64.8\% & 67.0\% \\
    \cite{ge2021yolox}YOLOX T & 87ms & 78.0\% & 86.4\% & 80.2\% & 83.2\% \\
    \cite{ge2021yolox}YOLOX S & 107ms & 82.6\% & 89.6\% & 84.3\% & 86.8\% \\
    \cite{ge2021yolox}YOLOX M & 194ms & 86.0\% & 95.3\% & 89.8\% & 92.5\% \\
    \cite{ge2021yolox}YOLOX L & 265ms & 87.3\% & 96.2\% & 90.7\% & 93.4\% \\
    \addlinespace
    G-YOLOv6 N & 32ms & 79.3\% & 87.4\% & 82.1\% & 84.7\% \\
    G-YOLOv6 S & 44ms & 83.6\% & 90.3\% & 85.6\% & 87.9\% \\
    G-YOLOv6 M & 93ms & 83.4\% & 90.1\% & 85.4\% & 87.7\% \\
    G-YOLOv6 L & 126ms & 85.8\% & 92.1\% & 87.5\% & 89.7\% \\
    \bottomrule
    \end{tabularx}
\end{table}

\subsection{Ablation Studies}

\subsubsection{Noise Distribution Strategy}

This ablation study explores the impact of different noise distribution strategies on model performance. We evaluated how variations in the applied noise affect the gating mechanism's effectiveness by experimenting with Gaussian, Uniform, and Gumbel noise distributions. The aim was to observe their influence on overall model accuracy and detection precision.

\begin{table}[ht]
    \centering
    \caption{Impact of Noise Distribution Strategies on Model Performance}
    \label{tab:noise_distribution}
    \begin{tabular}{@{}lccc@{}}
    \toprule
    Noise Strategy & Latency (\%) & mAP@0.5 (\%) & F1 Score (\%) \\ 
    \midrule
    Gaussian & Base & 52.5 & 58.1 \\
    Uniform & +5 & 52.4 & 58.0 \\
    Gumbel Noise & +3 & 52.6 & 56.3 \\
    \bottomrule
    \end{tabular}
\end{table}
    

\subsubsection{Feature Extractor}

This section analyzes the performance variations when employing different feature extractors within the gated architecture. By integrating ResNet-18, ResNet-50, and ResNet-101 as the backbone for feature extraction, we aim to discern the optimal combination that maximizes both accuracy and efficiency.

\begin{table}[ht]
    \centering
    \caption{Comparison of Feature Extractors in Gated Architecture}
    \label{tab:feature_extractor}
    \begin{tabular}{@{}lccc@{}}
    \toprule
    Feature Extractor & mAP@0.5 (\%) & F1 Score (\%) \\ 
    \midrule
    ResNet-18 & 52.0 & 58.1 \\
    ResNet-50 & 52.1 & 58.1 \\
    ResNet-101 & 52.3 & 58.2 \\
    \bottomrule
    \end{tabular}
\end{table}
    

\subsection{Discussion}

Our experiments demonstrate the G-YOLOv6 models' superior balance of high detection accuracy and low latency. On the VOC dataset, G-YOLOv6 models showed significant latency reductions while maintaining competitive accuracy, with the G-YOLOv6 N achieving 52.5\% mAP at 58ms, compared to YOLOv5 N's 61.3\% mAP at 83ms.

On the ROAD-SEC dataset, G-YOLOv6 models again excelled, with the G-YOLOv6 N achieving 79.3\% mAP at 32ms, versus YOLOv5 N's 86.0\% mAP at 88ms. Precision and recall metrics were strong, indicating robust performance.

Ablation studies on noise distribution and feature extractors showed slight variations, with deeper networks offering marginal gains. Overall, G-YOLOv6 models effectively balance efficiency and accuracy, proving ideal for resource-constrained environments.

\clearpage
